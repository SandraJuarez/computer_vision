{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the peppers image from this link https://blogs.mathworks.com/images/loren/173/peppers_BlueHills.png. Return a binary image (only 0s and 1s), with 1s corresponding to only the yellow peppers. Do this by setting a minimum and maximum threshold value on pixel values in the R,G,B channels. Note that you won’t be able to perfectly capture the yellow peppers, but give your best shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"peppers.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"peppers.png\", width=300, height=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read an image  \n",
    "image=cv2.imread('peppers.png')\n",
    "\n",
    "#treshold=[90,180,220]\n",
    "treshold=[90,190,150]\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        colors=image[i,j,:]\n",
    "        #print(colors)\n",
    "        if colors[0]<treshold[0] and colors[1]>treshold[1] and colors[2]>treshold[0]:\n",
    "            image[i,j,:]=[255,255,255]\n",
    "        else:\n",
    "            image[i,j,:]=[0,0,0]\n",
    "        \n",
    "        \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',image)\n",
    "# Espera una tecla para cerrar la ventana\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cierra todas las ventanas abiertas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"peppers_binary.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"peppers_binary.png\", width=300, height=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While RGB is the most common color space for images, it is not the only one. For example, one popular color space is HSV (Hue-Saturation-Value). Hue encodes color, value encodes lightness/darkness, and saturation encodes the intensity of the color. For a visual, see Fig. 1 of this wiki article https://en.wikipedia.org/wiki/HSL_and_HSV. Convert the image to the HSV color space using OpenCV’s cvtColor() function, and try to perform the same task by setting a threshold in the Hue channel. Add both binary images to your report. Which colorspace was easier to work with for this task, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('peppers.png')\n",
    "#converto hsv color space\n",
    "image=cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#define the range of yellow color in HSV\n",
    "lower_yellow = np.array([20, 100, 240])\n",
    "upper_yellow = np.array([60, 255, 255])\n",
    "\n",
    "# Threshold the HSV image to get only yellow colors\n",
    "mask = cv2.inRange(image, lower_yellow, upper_yellow)\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(image,image, mask= mask)\n",
    "\n",
    "cv2.imshow('res',res)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('image',image)\n",
    "# Espera una tecla para cerrar la ventana\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cierra todas las ventanas abiertas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"peppers_hsv.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"peppers_hsv.png\", width=300, height=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write separate functions that output the 3 x 3 transformation matrices for the following\n",
    "transforms: translation, rotation, similarity (translation, rotation, and scale), and affine. The\n",
    "functions should take as input the following arguments\n",
    "\n",
    "1. Translation: horizontal and vertical displacements\n",
    "2. Rotation: angle\n",
    "3. Similarity: angle, horizontal/vertical displacements, and scale factor (assume equal scaling for horizontal and vertical dimensions)\n",
    "4. Affine: 6 parameters\n",
    "\n",
    "The output of each function will be a 3 x 3 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traslation_matrix_2d(traslation_x, traslation_y):\n",
    "    return np.array([[1,0,traslation_x],[0,1,traslation_y],[0,0,1]])\n",
    "\n",
    "def rotation_matrix_2d(angle):\n",
    "    return np.array([[np.cos(angle),-np.sin(angle),0],[np.sin(angle),np.cos(angle),0],[0,0,1]])\n",
    "\n",
    "def similarity_matrix_2d(traslation_x, traslation_y, angle,scale_factor):\n",
    "    traslation_matrix=traslation_matrix_2d(traslation_x, traslation_y)\n",
    "    rotation_matrix=rotation_matrix_2d(angle)\n",
    "    scale=np.array([[scale_factor,0,0],[0,scale_factor,0],[0,0,1]])\n",
    "    return np.dot(traslation_matrix,np.dot(rotation_matrix,scale))\n",
    "\n",
    "def affine_matrix_2d(traslation_x, traslation_y, angle,scale_factor,shear_factor_x,shear_factor_y):\n",
    "    similarity=similarity_matrix_2d(traslation_x, traslation_y, angle,scale_factor)\n",
    "    shear=np.array([[1,shear_factor_x,0],[shear_factor_y,1,0],[0,0,1]])\n",
    "    return np.dot(similarity,shear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0 100]\n",
      " [  0   1  67]\n",
      " [  0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "tmatrix=traslation_matrix_2d(100, 67)\n",
    "print(tmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5       -0.8660254  0.       ]\n",
      " [ 0.8660254  0.5        0.       ]\n",
      " [ 0.         0.         1.       ]]\n"
     ]
    }
   ],
   "source": [
    "tmatrix=rotation_matrix_2d(np.pi/3)\n",
    "print(tmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5  -0.15 10.  ]\n",
      " [-0.4  -0.5  10.  ]\n",
      " [ 0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "amatrix=affine_matrix_2d(10, 10, np.pi,0.5,0.3,0.8)\n",
    "print(amatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
